# 模型选择与过拟合、欠拟合

## 概念介绍

1. 训练集、验证集、测试集的辨析(training, validation, testing dataset)
2. k-折交叉验证(计算机线性增加，往往在小型数据集上)
   - 充分考虑计算代价是否可以接受
   - k个模型是voting，还是选最好的，还是使用该超参数在晚上数据集上训练都可以
3. 模型过拟合和欠拟合(与数据和模型容量相关)
4. 模型容量对under/over fitting的影响，影响模型复杂度的因素
   1. 模型算法的中种类(MLP, CNN, RNN, Tr)
   2. 模型参数量、已经参数值的选择范围
5. VC维:对于一个分类模型，模型能够完美分类的数据集大小(DL中很少用，因为计算CV很困难)
6. 数据复杂度对于under/over fitting的影响，影响数据复杂度的因素
   1. 数据集大小(num_samples)
   2. 样本中所含信息量大小(样本中元素个数，图片分辨率(空间信息)，时序信息(时间信息))
   3. 数据集的多样性

## 代码

```python

features = np.random.normal(size=(n_train + n_test, 1))
np.random.shuffle(features)
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))    # boradcast


```

## 整理

- 模型容量需要匹配数据复杂度，否则容易导致过拟合欠拟合问题，虽然统计学习提供数学工具衡量模型复杂度，实际上我们观测训练误测和验证误差来衡量。
- 在真实应用中，我们往往增大模型容量，而后通过各种手段控制器容量，使其泛化误差下降。
- 过拟合不一定是件坏事，因为我们更关心验证误差，而不是训练误差和验证误差的差距。
- 当数据集不平衡时，我们如何对数据进行划分
  1. 首先考虑实际应用场景，是否也会出现数据不平衡，而后衡量验证集是否也需要同样比例的类间不均衡。(验证集往往是需要类间均衡的)
  2. 考虑使用样本复制的手段减弱类间不均衡的影响
  3. 也需要考虑使用loss加权来解决。
